### Понятие ОС

![[../_resources/Pasted image 20241103122558.png]]
- ОС - менеджер аппаратного обеспечения, менеджер железа
- ОС - не только ядро, это все необходимое для работы. Ядро - только часть ОС, которая связывает все части ОС
- Даже компилятор - не часть ОС, ОС достаточно скомпилировать один раз и далее она работает
- Память ядра, код ядра, его процесс - все это пространство именуется kernel space
- У kernel есть права на работу с железом
	- выделение физической памяти
	- запись на диск
	- и тд
- Код может работать в:
	- User mode - наш пользовательский код
	- Kernel mode - исполнение кода ядра
- Например, системный вызов write(), сделанный в user mode, инициирует переключение на kernel mode и исполнение кода ядра
- В микроядрах часть процессов ОС находятся в user space(например, coreaudiod, bluetoothd демоны и тд), эти прцоессы могут рабоать с ядром

![[../_resources/Pasted image 20241103124057.png]]
- Пользовательский код может обращаться к функционалу ядра через syscalls
- То есть вызов происходит в процессе из user space --> прокидывание аргументов через стек процесса и регистра в ядро --> исполнение кода ядра в другом процессе(в процесес ядра)
![[../_resources/Pasted image 20241103130220.png]]
- Аппаратные прерывания
	- Сигнал приходит на процессор(через провод, bluetooth etc)
	- Если на данный момент ядро занято критической работой, прерывания выстраиваются в очередь
	- Вызывается handler прерывания
	- Процессор отличает типы прерываний по номеру, источник прерывания - по пину, на который пришло прерывание(известны заранее) 
- When an interrupt occurs, the CPU stops executing the current running program, switches to kernel mode, executes interrupt handler. This handler saves the state of CPU, performs its operations, restores the state and returns to user mode
![[../_resources/Pasted image 20241103130918.png]]
- Прерывания обрабатываются по очереди одно за одним ***в отдельном стеке(?)***
- Обработка прерывания - создание задачи на обработку в очереди задач в коде ядра, исполнение задач в отдельных воркерах
- Top-bottom half design pattern
	- Top-half - первичная обработка здесь сейчас с требованиями по скорости
	- Bottom-half - основная обработка в менее критическом контексте

![[../_resources/Pasted image 20241103132239.png]]
- Запуск ядра производится Bootloader'ом(загрузчиком) - он ищет исполняемый файл выбранной ОС(или default os) и запускается его
- Загрузчик же вызывается программой BIOS - встроенное ПО, которое запускается при подаче питания(который инициируется нажатием кнопки запуска)
- Это программный код, который подрубает все железо в системе. программа BIOS ищет код bootloader на диске и передает ему управление
- Код программы BIOS сохраняется в read only memory(***ROM*)*** - физическое устройство, куда хардкодится embedded программа(встраивается производителем железа)
- При подаче электрического сигнала программа исполняется 
- ***Каким образом код BIOS попадает из ROM на процессор?***(Исполнять код может только процессор)
	- При подаче стартует в том числе процессор
	- В момент запуска на процессоре отсутствуют инструкции для исполнения
	- Процессор детектит это состояние и выполняет инструкцию ***jump***(аля go-to) пряо на адрес начала программы BIOS в ROM(это адрес известен процессору заранее)

![](../_resources/Pasted%20image%2020241103135837.png)
- BIOS - работает напрямую с железом, аппаратно зависимый софт, позволяет управлять железками
- подрубает все устройства, подключенные к материнской плате

- Сам BIOS устроен как можно проще, поскольку программа ограничена малым объемом ROM
- Чтобы bios найти загрузчик, нужно предоставить ему понятную ему структуру хранения информации о нахождении программы
- BIOS-совместимые устройства содержат, например, в начале памяти некую структуру с оффсетом от начала памяти устройства, с оффсетом до кода загрузчика
- BIOS стартует загрузчик и заканчивает исполнение

- Загрузчик уже может быть много сложнее, поскольку не ограничен объемом ROM



![](../_resources/Pasted%20image%2020241103140000.png)
- ***PIpeline:***
	- Подача питания --> jump процессора на код bios --> исполнение bios(нахождение загрузчика, запуска загрузчика, завершение) --> исполнение загрузчика(запуск, запуск ядра, завершение) --> запуск ядра



- ***docker run - запуск неймспейса в 1-ом ядре***

### Ядро Linux. Процессы

![](../_resources/Pasted%20image%2020241103143842.png)


![](../_resources/Pasted%20image%2020241103144214.png)


![](../_resources/Pasted%20image%2020241103144557.png)

- Состояние процесса
- использование cpu
- на каком ядре процессора запущен
- приоритет


![](../_resources/Pasted%20image%2020241103144648.png)
- Оперативная память процесса(виртуальная память, которая мапится на оперативную)
- Коды завершения

![](../_resources/Pasted%20image%2020241103144828.png)
- pid процесса
- указатель на родителя
- дочерние процессы
- *можем вытаскивать данные этой структуры через некоторые syscalls, например, pid()*


![](../_resources/Pasted%20image%2020241103145025.png)
- credentials
	- юзер процесса
	- его доступы, группы, права
- files - таблица файловых дескрипторов, которая наполняется при открытии файлов, сокетов и тд
	- вызывая syscalls типа `open` и проч получаем индекс в этой таблице


#### жизненный цикл процесса
![](../_resources/Pasted%20image%2020241103145543.png)
- Создается системным вызовов `fork()`
- Ставится исполняться на какое-то  ядро шедулером
- Исполняется
- ***может быть в ожидании какого-то события(данные из сокета и тп)*** - по сути процесс заблокирован - не шедулится планировщиком, не есть процессорное время, занимает только память
- Решедулинг
- Исполнение
- ...
- Окончательное завершение - ***terminated***


- ! ядро не оперирует понятиями ***поток*** и ***процесс*** (как в userspace) - оно оперирует понятием ***task***
- ближайшая аналогия таску в userspace - это поток
- можно говорить, что `task_struct` ядра - это однопоточный процесс
- в коде ядра линукса потоки процесса никак не группируются в некие структуры данные аля `threads` и т.п. - потоки процесса объединены только лишь схожими занчениями некоторых полей структуры данных `task_struct`(виртуальная память, таблица fd, pid и т.п.)
- ***ядро не шедулит процессы, оно шедулит задачи(то есть скорее шедулит потоки)***

#### Работа с железом
![](../_resources/Pasted%20image%2020241103151307.png)
- Устройства взаимодействуют с ядром через ***драйвера*** - программы, которые загружаются в ядро
	- статически - если уже есть в ядре из коробки
	- динамически(.so библиотека) - подгружаются в ядро при установке новых драйверов
	- драйвер уже работает с устройствами, то есть это ***прослойка между ОС и устройствами***

##### Группировка нижележащих слоев в абстракцию для слоя уровнем выше
- Множество различных, например, HDD дисков разных производителей удовлетворяет некоему стандарту(контракту) - то есть по сути имплементирует некий интерфейс, набор команд, которые должно уметь выполнять устройство(как - не важно), чтобы быть compatible со стандартом --> в таком случае ***драйвер(абстракция над аппаратным устройством)***  будет подавать строго стандартизованный набор процессорных команд на устройство, а конкретное устройство уже исполняет команду по-своему --> таким образом, множество конкретных HDD дисков схлопывается в сущность HDD диска. Драйвер HDD диска работает именно с этой сущностью, не с конкретной ее реализацией. Это абстракция существует, чтобы избежать необходимости подключать в ядро миллион конкретных драйверов для конкретной модели устройства
- На уровне выше, различные устройства(HDD, SSD, сетевые карты и т.п.) - по сути, их драйвера - схлопываются в сущность ***устройство ввода-вывода***, с которой работает уже ядро ОС.
	- То есть в ядре нет кода обработки команд драйвера HDD, SSD и т.п. - вместо этого работает с абстракцией(интерфейсом) - на уровне кода это в прямом смысле интерфейс, в C - это набор указателей на функции т.н. называемого устройство ввода-вывода(`read, write, close, open, seek` и т.п.)
![](../_resources/Pasted%20image%2020241103160439.png)


![](../_resources/Pasted%20image%2020241103161034.png)
![](../_resources/Pasted%20image%2020241103161055.png)


#### Время
![](../_resources/Pasted%20image%2020241103173223.png)

- Время в ядре дискретно:
	- На материнке находится осциллятор, который раз в некоторое время генерирует сигнал(тик), этот тик обрабатывается как прерывание, соответствующий обработчик в коде ядра инкрементит счетчик времени 

![](../_resources/Pasted%20image%2020241103173820.png)
![](../_resources/Pasted%20image%2020241103173855.png)
- Осциллятор генерирует колебания
	- подача электрического сигнала
	- возбуждение магнитного поля
	- изменение свойств кристалла в известной из физики периодичностью
- Контроллер осциллятора агрегирует эти колебания - посылает прерывание в процессор, оно обрабатывается в ядре

![](../_resources/Pasted%20image%2020241103174042.png)
- CONFIG_GZ - константа кол-ва прерываний в секунду
	- перенастраивается, но для этого нужно пересобрать ядро, в рантайме никак

![](../_resources/Pasted%20image%2020241103175502.png)
- Устройство RTC
	- тикает когда система отрублена, за счет батарейки
	- внутри такой же осциллятор, только уже не напрямую в материнке, а в RTC, сам RTC на материнке


![](../_resources/Pasted%20image%2020241104124103.png)
- PPS - устройство, позволяющее тикать с максимальной физической точностью
	- внутри атом цезия переходит из 1-ого состояния в другое в изолированных условиях(время переход атома есть секунда)
	- контроллер снимает показания и по кабелю передает как прерывание на процессор
- С помощью PPS можно решать задачу синхронизации скорости хода времени, приводить частоту тиков к максимально точной, канонической
	- тики от RTC буду обрабатываться так, чтобы синхронизироваться с тиками PPS, путем инкремента счетчика времени на меньшее значение
- usecase - ***google spanner***
	- обработка транзакций разных инстансов без явной синхронизации машин по сети - благодаря pps время на разных машинах идет синхронно и можно понять, какая транзакция была раньше, какая позже


#### VFS

![](../_resources/Pasted%20image%2020241104125139.png)
- ОС работает не с конкретными файловыми системами, а с т.н. ***виртуальной файловой системой***, то есть можно реализовать файловую систему, реализовав указанный нобар функций
- реализованная ФС подключается в ядро - добавляется структура с проинициализированными указателями на функции

> A **function** **pointer**, also called a subroutine **pointer** or procedure **pointer**, is a **pointer** that **points** to a **function**. As opposed to referencing a data value, a **function** **pointer** **points** to executable code within memory. Dereferencing the **function** **pointer** yields the referenced **function**, which can be invoked and passed arguments just as in a normal **function** call. (https://stackoverflow.com/questions/840501/how-do-function-pointers-in-c-work)

> **Указатель на функцию** — это выражение или переменная, которые используются для представления адреса функции. Указатель содержит адрес первого байта в памяти, по которому располагается выполняемый код функции.



#### IPC
![](../_resources/Pasted%20image%2020241104131035.png)


#### Users, groups, permissions
![](../_resources/Pasted%20image%2020241104131216.png)
- Проверка permissions
	- файлы, объекты IPC и проч обладают маской доступа, при совершении манипуляций с объектами ядро сверяет маску и креды процесса


#### Task scheduling
![](../_resources/Pasted%20image%2020241104162415.png)
- Cooperative multitasking - таска сама решает, когда ее нужно снять с ядра процессора - небезопасно
- Preemptive - таска вытесняется шедулером
- В ядре кооперативной многозадачности нет, однако она может быть полезна в userspace
	- корутины(файберы, green threads) - пример многозадачности
		- могут быть stackless, stackful - по сути это контекст исполнения
		- корутины исполняются `task struct`'ами - задача балансить множество корутин между выделенным числом `task struct`'s (создавать на каждую задачу новый `task struct` крайне затратно по ресурсам) 

> писать в рамках корутины линейный код



##### i/o bound, cpu bound
![](../_resources/Pasted%20image%2020241104165747.png)
- ***cpu bound*** - задачи, которые исполняет код, требующий бОльших затрат cpu(вычисления, обработка транзакций etc) - то есть задачи этого класса следует держать на процессоре как можно больше --> то есть тут в приоритете не скорость переключения на задачу, а ***суммарное время исполнения на ядре процессора***
- ***i/o bound*** - тут наоборот: сама по себе задача занимает немного cpu time в своей активной фазе(парсинг пакетов и тп), однако она может ждать своего часа неопределенное время, а когда он наступает, необходимо оперативно дать ей контроль(например, из-за требований по latency в случае сетей) - то есть тут в приоритете ***скорость переключения на задачу***

> пользователь ос - классический пример i/o bound задачи: долгое по сравнению с процессором время отклика(ввод данных и тп), однако сама задача(обработка клика, нажатия) 
> 	1. требует быстрой реакции на нее
> 	2. не затратна по cpu


##### приоритеты задач, распределение cpu time
![](../_resources/Pasted%20image%2020241104170743.png)
- Можем задавать приоритет задачи через syscalls


![](../_resources/Pasted%20image%2020241104171716.png)
- Конвертация видео - cpu bound задача
- Игра в шахматы - i/o bound задача

![](../_resources/Pasted%20image%2020241104172243.png)
- Планировщик распределяет ***квант времени(конфигурируемое значение)*** на каждую из задач не как строго определенное, абсолютное(в мс), а в процентном соотношении
- Причем каждой из тасок ***гарантируется некая минимальная доля кванта времени***
- Причем если задаче не нужно все время, определенное ей в %, она отдает его другим нуждающимся таскам



![](../_resources/Pasted%20image%2020241104173228.png)

- Переключаться между задачами максимально часто(в пределе - постоянно(максимально близко к эффекту параллелизма)) - не имеет смысла --> есть некий ***минимальный порог переключения*** - минимальное время работы задачи, меньше которого ей работать нет смысла, поскольку в таком случае оверхед на switching будет уже больше самой полезной работы

> минимальный порог переключения - прямая аналогия с максимальной частотой обработки тиков: нет смысла считать время максимально точно, т.к. каждый тик подразумевает его обработку --> как следствие, слишком большой оверхед


##### структура хранения задач в ядре
![](../_resources/Pasted%20image%2020241104174027.png)
- `sched entities` хранятся в красно-черном дереве
- `waiting` таски там не хранятся, то есть они вообще никак не влияют на процесс выбора следующей задачи


![](../_resources/Pasted%20image%2020241123153015.png)
- Процесс реагирует на прерывания, это могут быть:
	- решедулинг с физического ядра
	- критические ошибки - исключения(0 division, seg fault, запись в protected память etc)
	- сигналы

![](../_resources/Pasted%20image%2020241123153157.png)
---
https://slides.com/gerold103/sysprog_eng1


![](../_resources/Pasted%20image%2020241123153218.png)
- Можно анализировать core дампы(снимки памяти процесса перед падением) через спец утилиты
