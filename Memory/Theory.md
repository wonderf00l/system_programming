
![](../_resources/Pasted%20image%2020241109170111.png)

##### Регистры
![](../_resources/Pasted%20image%2020241109170133.png)
- Регистры находятся прямо на процессоре, физически занимают место на процессоре
- Их нельзя заменить/обновить
- Это энергозависимая память, при рестарте данные не сохраняются
- тут нет никакой виртуализации памяти, это буквально ячейки памяти, в которые процессор пишет, из которых читает
- У каждого регистра есть свое название
- Скорость доступа - один такт процессора



![](../_resources/Pasted%20image%2020241109170540.png)


![](../_resources/Pasted%20image%2020241109174149.png)
- В процессор вшиты массивы битов - как раз регистры
- Можно адресовывать все биты или часть массива
- Технически каждый бит представлен т.н. D-Latch'ем
	- http://simplecpu.com/memory.html
	- это триггер, который позволяет сохранять переданное значение

![](../_resources/Pasted%20image%2020241109175018.png)
- Типы регистров:
	- Внутренние - их использует сам процессор под определенные нужды
	- Регистры общего назначения - для процессора все одинаковые, однако есть договоренности, какой регистр под что использовать(например, в какой-то регистр положить номер syscall'а, в другой что-то еще и тд)



##### CPU cache
![](../_resources/Pasted%20image%2020241111235116.png)
- Кэш-память хранит некую часть данных/инструкций оперативной памяти
- Кэш появился из-за возросшей разницы между скоростью работы процессора и оперативной памяти - со временем ОЗУ стала ***бутылочным горлышком***: процессор начал простаивать, пока данные доходили из озу по шине

>Процессор взаимодействует только с cpu cache, поход напрямую в ОЗУ происходит только в том случае, если адреса ячейки памяти, к которой нужно обратиться процессору, нет в cpu cache

- Кеш быстрее ОЗУ по 2-ум причинам:
	- Расположен на процессоре, физически ближе к процессору
	- Считывание байт памяти процессором происходит напрямую, не через шину данных

###### локальность кеша
![](../_resources/Pasted%20image%2020241111235735.png)
- Локальность по времени - данные, которые сейчас используются, вероятно, снова понадобятся через какое-то время
- Локальность по расположению - данные, находящиеся недалеко от текущей обрабатываемой ячейки, скорее всего, понадобятся при дальнейшей обработке


![](../_resources/Pasted%20image%2020241112000104.png)
- На 1-ом уровне память явно разделена на память с инструкциями, память с данными
	- видимо, связано с разной локальностью секций с инструкциями и данными: инструкции - в основном пространственная локальность кеша; данные - и пространственная, и по времени
	- на 1-ом уровне кеша видима это разделение важно для перфа

![](../_resources/Pasted%20image%2020241123182453.png)
- Подобное ограничение размера кеша и разделение на уровни - видимо, опытно и исторически полученный оптимальный сетап
	- чтобы учесть trade off между "как долго идти до памяти"(как долго электрический сигнал доходит до нужных элементов) и "как долго искать в памяти"(как быстро пройдемся по транзисторам,триггерам памяти и тп)
	- ну то есть сделать один огромный L1 кеш видимо оказалось не самым эффективным вариантом 

![](../_resources/Pasted%20image%2020241123182722.png)


#### Типы организации кешей, алгоритмы чтения из кешей
![](../_resources/Pasted%20image%2020241124154015.png)
- ***Inclusive*** - кеши внешних уровней содержат данные кешей внутренних
- ***Exclusive*** - кеши разных уровней НЕ содержат общие данные
- ***NINE*** - кеши, которые могут содержать на соседних уровнях одинаковые данные(not exclusive), при этом внутренние уровни могут содержать данные, которых нет на внешних(not inclisuve)

> Сложность Inclusive/Exclusive кешей - поддержание этой самой инклюзивности/эксклюзивности - алгоритмически и аппаратно
> 	в случае ***inclusive*** - нужно синхронизировать уровни между собой, чтобы внешние уровни обязательно содержали данные внутренних
> 	в случае ***exclusive*** - та же синхронизация, только для поддержания того, чтобы данные разных уровней не пересекались
> Поэтому на практике используется NINE подход
> ![](../_resources/Pasted%20image%2020241124154713.png)


![](../_resources/Pasted%20image%2020241124154619.png)
- Если кеш уровня ***i-1*** переполняется, его данные уходят на уровень ***i***


#### запись в кеш
![](../_resources/Pasted%20image%2020241124181816.png)
- ***Write throught policy*** - запись в адрес производится в кеши всех уровней, а также в оперативную память - то есть все синхронно и крайне медленно, процессор зависит от скорости доступа к ОЗУ
- ***Write back***(используется этот вариант)
	- процессор работает только с кешем
	- запись производится в кеш, адреса, в которые записал что-то процессор(то есть они уже не из оперативной памяти), помечаются специальным dirty bit - помеченные записи не будут вытеснены из кеша без записи в озу
	- далее асинхронно такие записи вытесняются на уровни выше, пока не ***sync'ануться*** в ОЗУ уже самим кешем
	- кеш может собрать батчи таких записей и все их зафлашить в озу


![](../_resources/Pasted%20image%2020241124182607.png)
- Кеш можно представить как некую структуру данных, по ключу хранящую ***физический*** адрес(начало блока физической памяти), по значению - саму страницу(блок) физической памяти(ОЗУ)
- Адрес физический, а не виртуальный - во избежании коллизий при обращении 2-ух разных процессов к одному и тому же виртуальному адресу, тогда программы мешали бы друг другу
- Кеш оперирует кеш-линиями - этими самыми блоками фиксированного размера(обычно 64 байта)
- Алгоритм чтения из кеша примерно следующий:
	- из полученного адреса извлекаем адрес начала кеш-линии, оффсет от начала(addr & (2^6)-1)
	- по адресу начала блока находим блок физической памяти
	- делаем оффсет в рамках блока, получаем искомый адрес, пишем по нему байт, читаем байт(ы) 


![](../_resources/Pasted%20image%2020241124211840.png)
- Есть разные подходы, как физический адрес озу будет интерпретироваться кешем, то есть каким образом кусок памяти размером 64 байта(линия) отобразится в кеш(кеш-линию). то есть где будет лежать этот кусок в кеше физически

![](../_resources/Pasted%20image%2020241124212818.png)
1. Одноассоциативный кеш
	- Блок памяти озу, адрес его начала отображается в кеш ровно 1-им конкртеным образом, то есть он будет располагаться в кеше ровному по 1-ому конкретному индексу(если мыслить кеш как некий harware array) - иначе говоря, для этого физического блока ровно одна ассоциация в cpu cache
	- Алгоритмически проще, т.к. при работе с конкретным адресом в программе мы сразу можем узнать, где в кеше располагается блок памяти, в который входит этот адрес - знаем мы это исходя из address layout - 32 бита адреса являются тем самым индексом. --> при таком подходе не осуществляется full scan кеша для поиска блока, начало адреса которого мы извлекли из полного адреса ячейки 
	- Неизбежно n блоков озу мапятся в 1 блок в кеше --> чтобы их различать, используются первые 26 бит адреса
	- Очевидна проблема с частыми коллизиями и вытеснениями из кеша: 
		- если разные разрозненные блоки озу отображаются в кеш в одну линию -> если программа постоянно работает именно с такими блоками, обращается именно к таким адресам, эти блоки будут попеременно вытесняться из этой самой линии при обращении к ним, например, в цикле

![](../_resources/Pasted%20image%2020241124212838.png)
2. N-ассоциативный кеш(n ассоциаций для ram block в cpu cache)
	- подход тот же, однако тут блок основной памяти может мапиться в n блоков памяти cpu cache
	- тогда при обращении к какому-то адресу интерпретируем его согласно уже другому layout:
		1. получаем адрес начала блока(кеш-линии)
		2. проходимся по подмассиву индексов-мест, в которые данный блок мог отобразиться в кеше
	- за счет расширения мест, куда может попасть блок в кеше уменьшаем коллизии и вытеснения 

![](../_resources/Pasted%20image%2020241124212030.png)
3. Полностью ассоциативный кеш(C-ассоциативный кеш, где C - размер кеша) - (число ассоциаций для ram block - число кеш-линий)
	- Иначе говоря, любой блок озу может отобразиться в любую кеш-линию в cpu cache
	- Более простой address layout, более интуитивно
	- Но страдает энергопотребление, т.к. при получении адреса начала кеш-линии мы пойдем full scan'ом по всему кешу в поисках блока - физически это реализуется через пропускание эл. заряда через весь кеш
	- Минимум коллизий, максимум производительности, максимум энергопотребления - ***работает на L1***


#### Параллелизм на уровне инструкций(instruction level parallelism)
![](../_resources/Pasted%20image%2020241130204750.png)
- Конвейерная обработка инструкций процессором - в 5 этапов
- Инструкции одного потока исполнения(потока инструкций, иначе, просто потока-треда-tast struct'а) могут исполняться ядром процессором параллельно
- Отличается от параллелизма на уровне потоков исполнения(потоков инструкций) - когда несколько ядер процессора исполняют потоки инструкций параллельно. При этом каждое из ядер распараллеливает исполнение своего потока инструкций

---
https://slides.com/gerold103/sysprog_eng3